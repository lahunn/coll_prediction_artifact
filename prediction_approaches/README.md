# `prediction_approaches` 文件夹分析

该文件夹包含了用于机器人运动规划中碰撞预测的多种哈希(Hashing)方法的实现、评估和可视化的相关代码。这些方法旨在通过快速查询历史数据来预测一个给定的机器人状态是否会发生碰撞,从而避免昂贵的实时碰撞检测计算。

核心思想是将高维的机器人状态(如关节角度、末端执行器坐标)通过不同的哈希函数映射为低维的哈希键,并记录每个哈希键对应的碰撞/非碰撞频率。当遇到新的状态时,通过查询其哈希键来预测碰撞概率。

文件夹下的文件可以分为以下几类:

## 1. 核心哈希算法 (`.py`)

这些 Python 脚本实现了不同的哈希策略。

- **`pose_hashing.py`**:
  - **作用**: 实现基于机器人**原始关节姿态(Pose)**数据的哈希方法。
  - **输入**: 从 `_pose.pkl` 文件中读取机器人的关节角度。
  - **方法**: 将关节角度进行离散化(digitize),然后通过不同的组合方式(完整哈希、部分哈希、折叠哈希)生成哈希键,存入哈希表并进行碰撞预测。

- **`coord_hashing.py`**:
  - **作用**: 实现基于机器人末端执行器**原始坐标(Coordinate)**的哈希方法。
  - **输入**: 从 `_coord.pkl` 文件中读取末端执行器的坐标。
  - **方法**: 与 `pose_hashing.py` 类似,但处理的是三维坐标数据。它通过调整一个敏感度参数 `S` 来控制哈希表的更新策略,是多个实验的核心脚本。

- **`enpose_hashing.py`**:
  - **作用**: 实现基于**编码后(Encoded)**的机器人姿态的哈希方法。
  - **输入**: 原始姿态数据 (`_pose.pkl`)。
  - **方法**: 使用一个预训练的神经网络模型(`models_new.py`)将高维的姿态数据压缩(编码)成低维的向量,然后对这个低维向量进行哈希。此脚本需要 GPU (`.cuda()`) 来运行模型。

- **`enpose_hashing_cpu.py`**:
  - **作用**: `enpose_hashing.py` 的 CPU 版本。
  - **方法**: 它不实时进行编码,而是直接加载已经由 GPU 预先计算并保存好的编码向量 (`low_obstacle_encodepose.pkl`, `high_obstacle_encodepose.pkl`),从而可以在没有 GPU 的环境下运行。

- **`encoord_hashing.py`**:
  - **作用**: 实现基于**编码后(Encoded)**的坐标数据的哈希方法。
  - **方法**: 结合了 `coord_hashing.py` 和 `enpose_hashing.py` 的思想,对编码后的坐标向量进行哈希处理。

- **`models_new.py`**:
  - **作用**: 定义了实验中使用的神经网络模型。
  - **内容**: 包含一个 `ResNet` 类,它似乎是一个用于降维和特征提取的自动编码器(Auto-encoder)结构。

## 2. 实验启动与复现脚本 (`.sh`)

这些 Shell 脚本用于自动化地执行实验并生成图表。

- **`launch.sh`**:
  - **作用**: 运行一系列基准测试,对比 `pose_hashing`, `enpose_hashing`, `encoord_hashing`, 和 `coord_hashing` 等多种哈希方法在**低密度**和**高密度**障碍物场景下的性能。
  - **输出**: 将所有实验的精度(Precision)和召回率(Recall)结果分别存入 `result_files/result_low.csv` 和 `result_files/result_high.csv`。

- **`launch_coord.sh`**:
  - **作用**: 专门用于评估 `coord_hashing.py` 算法在不同**敏感度阈值(S)**下的性能。
  - **输出**: 为低、中、高三种障碍物密度生成对应的 `.csv` 结果文件。

- **`launch_fig14.sh`**:
  - **作用**: 评估 `coord_hashing.py` 在不同**更新频率(U)**下的性能。

- **`fig9.sh`, `fig13.sh`, `fig14.sh`**:
  - **作用**: 一键复现论文中的图 9、图 13 和图 14。
  - **流程**: 每个脚本首先调用对应的 `launch_*.sh` 脚本来运行实验并生成数据,然后调用 `plot_*.py` 脚本来根据数据绘制图表。

## 3. 结果可视化脚本 (`.py`)

这些脚本使用 `matplotlib` 库将 `.csv` 文件中的实验数据转换成图表。

- **`plot_fig9.py`**:
  - **作用**: 读取 `result_low.csv` 和 `result_high.csv` 的数据,生成对比不同哈希函数(POSE, ENPOSE, COORD 等)性能的柱状图,对应论文图 9。

- **`plot_fig13.py`**:
  - **作用**: 读取 `launch_coord.sh` 生成的数据,展示 `COORD` 方法在不同敏感度 `S` 下的精度、召回率和计算成本,对应论文图 13。

- **`plot_fig14.py`**:
  - **作用**: 读取 `launch_fig14.sh` 生成的数据,展示 `COORD` 方法在不同更新频率 `U` 下的性能,对应论文图 14。

## 4. 数据与结果文件

- **`result_files/` (文件夹)**:
  - **作用**: 存放所有 `launch` 脚本运行后生成的 `.csv` 格式的原始数据。

- **`*.csv` (文件)**:
  - **内容**: 保存实验结果,通常每行包含两个值: 精度(Precision)和召回率(Recall)。

- **`*.pkl` (文件)**:
  - **内容**: `pickle` 格式的二进制文件,用于存储 Python 对象。在这里,它们主要用来存储预先计算好的编码姿态数据,以加速 CPU 上的实验。

- **`*.pdf` (文件)**:
  - **内容**: 由 `plot_*.py` 脚本生成的最终图表,是论文中图表的直接来源。

综上所述,该文件夹构成了一个完整的学术实验流程: 从实现多种算法、通过启动脚本进行批量实验、将结果保存为数据文件,到最终通过绘图脚本将数据可视化为论文图表。
